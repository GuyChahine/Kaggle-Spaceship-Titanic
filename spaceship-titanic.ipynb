{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"data/train.csv\").sample(frac=1).reset_index(drop=True)\n",
    "test_data = pd.read_csv(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(data):\n",
    "    def feature_creation(data):\n",
    "        def passengerid(feature):\n",
    "            return pd.DataFrame({\n",
    "                \"Group\": [value[5:] for value in data[feature]]\n",
    "            })\n",
    "        def cabin(feature):\n",
    "            return pd.DataFrame({\n",
    "                \"Deck\": [value.split(\"/\")[0] if value is not np.nan else value for value in data[feature]],\n",
    "                \"Side\": [value.split(\"/\")[2] if value is not np.nan else value for value in data[feature]],\n",
    "            })\n",
    "        return_feature = lambda feature: data[feature]\n",
    "        feature_func = {\n",
    "            \"PassengerId\": passengerid,\n",
    "            \"HomePlanet\": return_feature,\n",
    "            \"CryoSleep\": return_feature,\n",
    "            \"Cabin\": cabin,\n",
    "            \"Destination\": return_feature,\n",
    "            \"Age\": return_feature,\n",
    "            \"RoomService\": return_feature,\n",
    "            \"FoodCourt\": return_feature,\n",
    "            \"ShoppingMall\": return_feature,\n",
    "            \"Spa\": return_feature,\n",
    "            \"VRDeck\": return_feature,\n",
    "        }\n",
    "        return [func(key) for key, func in feature_func.items()]\n",
    "    \n",
    "    def onehotencoding(f_df):\n",
    "        temp = pd.DataFrame()\n",
    "        for col in f_df.columns:\n",
    "            if f_df[col].dtype != float and f_df[col].dtype != int:\n",
    "                for uniq_value in f_df[col].unique():\n",
    "                    if uniq_value is not np.nan:\n",
    "                        temp = pd.concat([\n",
    "                            temp,\n",
    "                            pd.DataFrame({f\"{col}_{uniq_value}\": (f_df[col] == uniq_value).astype(float)})\n",
    "                        ],axis=1)\n",
    "            else:\n",
    "                f_df.loc[f_df[col].isnull(), col] = f_df[col].mean()\n",
    "                temp = pd.concat([\n",
    "                    temp,\n",
    "                    f_df[col]\n",
    "                ], axis=1)\n",
    "        return temp.reindex(temp.columns.sort_values(), axis=1)\n",
    "                \n",
    "    feature_df = pd.concat(feature_creation(data), axis=1)\n",
    "    return onehotencoding(feature_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_clean_data(data):\n",
    "    def feature_creation(data):\n",
    "        def passengerid(feature):\n",
    "            return pd.DataFrame({\n",
    "                \"Group\": [value[5:] for value in data[feature]]\n",
    "            })\n",
    "        def cabin(feature):\n",
    "            return pd.DataFrame({\n",
    "                \"Deck\": [value.split(\"/\")[0] if value is not np.nan else value for value in data[feature]],\n",
    "                \"Num\": [int(value.split(\"/\")[1]) if value is not np.nan else value for value in data[feature]],\n",
    "                \"Side\": [value.split(\"/\")[2] if value is not np.nan else value for value in data[feature]],\n",
    "            })\n",
    "        return_feature = lambda feature: data[feature]\n",
    "        feature_func = {\n",
    "            \"PassengerId\": passengerid,\n",
    "            \"HomePlanet\": return_feature,\n",
    "            \"CryoSleep\": return_feature,\n",
    "            \"Cabin\": cabin,\n",
    "            \"Destination\": return_feature,\n",
    "            \"Age\": return_feature,\n",
    "            \"RoomService\": return_feature,\n",
    "            \"FoodCourt\": return_feature,\n",
    "            \"ShoppingMall\": return_feature,\n",
    "            \"Spa\": return_feature,\n",
    "            \"VRDeck\": return_feature,\n",
    "        }\n",
    "        return [func(key) for key, func in feature_func.items()]\n",
    "    \n",
    "    def onehotencoding(f_df):\n",
    "        temp = pd.DataFrame()\n",
    "        for col in f_df.columns:\n",
    "            if f_df[col].dtype != float and f_df[col].dtype != int:\n",
    "                for uniq_value in f_df[col].unique():\n",
    "                    if uniq_value is not np.nan:\n",
    "                        temp = pd.concat([\n",
    "                            temp,\n",
    "                            pd.DataFrame({f\"{col}_{uniq_value}\": (f_df[col] == uniq_value).astype(float)})\n",
    "                        ],axis=1)\n",
    "            else:\n",
    "                f_df.loc[f_df[col].isnull(), col] = f_df[col].mean()\n",
    "                temp = pd.concat([\n",
    "                    temp,\n",
    "                    f_df[col]\n",
    "                ], axis=1)\n",
    "        return temp.reindex(temp.columns.sort_values(), axis=1)\n",
    "                \n",
    "    feature_df = pd.concat(feature_creation(data), axis=1)\n",
    "    return onehotencoding(feature_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_train_data = new_clean_data(train_data.drop(columns=[\"Transported\"]))\n",
    "clean_test_data = new_clean_data(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8693, 33), (8693, 1), (4277, 33))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(pd.concat([clean_train_data, clean_test_data], axis=0))\n",
    "x_train = scaler.transform(clean_train_data)\n",
    "x_test = scaler.transform(clean_test_data)\n",
    "y_train = np.where(train_data.Transported.to_numpy(), 1, 0).reshape(-1,1)\n",
    "x_train.shape, y_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Input, Dropout\n",
    "from keras.activations import relu, sigmoid\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import BinaryCrossentropy\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(layers):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=x_train.shape[1]))\n",
    "    for i, u in enumerate(layers):\n",
    "        if type(u) == float:\n",
    "            model.add(Dropout(u))\n",
    "        elif type(u) == int:\n",
    "            model.add(Dense(u, activation=relu))\n",
    "    model.add(Dense(1, activation=sigmoid))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = EarlyStopping(\n",
    "    monitor=\"val_accuracy\",\n",
    "    min_delta=0.0001,\n",
    "    patience=20,\n",
    "    verbose=1,\n",
    "    mode=\"max\",\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "783/783 [==============================] - 4s 5ms/step - loss: 0.5423 - accuracy: 0.7240 - val_loss: 0.4880 - val_accuracy: 0.7494\n",
      "Epoch 2/100\n",
      "783/783 [==============================] - 4s 5ms/step - loss: 0.4886 - accuracy: 0.7491 - val_loss: 0.4711 - val_accuracy: 0.7644\n",
      "Epoch 3/100\n",
      "783/783 [==============================] - 4s 5ms/step - loss: 0.4694 - accuracy: 0.7619 - val_loss: 0.4751 - val_accuracy: 0.7471\n",
      "Epoch 4/100\n",
      "783/783 [==============================] - 4s 5ms/step - loss: 0.4608 - accuracy: 0.7677 - val_loss: 0.4431 - val_accuracy: 0.7839\n",
      "Epoch 5/100\n",
      "783/783 [==============================] - 4s 5ms/step - loss: 0.4503 - accuracy: 0.7743 - val_loss: 0.4458 - val_accuracy: 0.7793\n",
      "Epoch 6/100\n",
      "783/783 [==============================] - 4s 5ms/step - loss: 0.4470 - accuracy: 0.7786 - val_loss: 0.4498 - val_accuracy: 0.7736\n",
      "Epoch 7/100\n",
      "783/783 [==============================] - 4s 5ms/step - loss: 0.4397 - accuracy: 0.7817 - val_loss: 0.4513 - val_accuracy: 0.7862\n",
      "Epoch 8/100\n",
      "783/783 [==============================] - 4s 5ms/step - loss: 0.4419 - accuracy: 0.7883 - val_loss: 0.4442 - val_accuracy: 0.7897\n",
      "Epoch 9/100\n",
      "783/783 [==============================] - 4s 5ms/step - loss: 0.4403 - accuracy: 0.7828 - val_loss: 0.4340 - val_accuracy: 0.8011\n",
      "Epoch 10/100\n",
      "783/783 [==============================] - 4s 5ms/step - loss: 0.4354 - accuracy: 0.7831 - val_loss: 0.4318 - val_accuracy: 0.7966\n",
      "Epoch 11/100\n",
      "783/783 [==============================] - 4s 5ms/step - loss: 0.4325 - accuracy: 0.7936 - val_loss: 0.4247 - val_accuracy: 0.7908\n",
      "Epoch 12/100\n",
      "783/783 [==============================] - 4s 5ms/step - loss: 0.4308 - accuracy: 0.7901 - val_loss: 0.4422 - val_accuracy: 0.7782\n",
      "Epoch 13/100\n",
      "783/783 [==============================] - 4s 5ms/step - loss: 0.4258 - accuracy: 0.7915 - val_loss: 0.4320 - val_accuracy: 0.7966\n",
      "Epoch 14/100\n",
      "783/783 [==============================] - 4s 5ms/step - loss: 0.4269 - accuracy: 0.7910 - val_loss: 0.4335 - val_accuracy: 0.7908\n",
      "Epoch 15/100\n",
      "783/783 [==============================] - 4s 5ms/step - loss: 0.4297 - accuracy: 0.7945 - val_loss: 0.4353 - val_accuracy: 0.7908\n",
      "Epoch 16/100\n",
      "783/783 [==============================] - 4s 5ms/step - loss: 0.4157 - accuracy: 0.7984 - val_loss: 0.4250 - val_accuracy: 0.7851\n",
      "Epoch 17/100\n",
      "783/783 [==============================] - 4s 5ms/step - loss: 0.4194 - accuracy: 0.7976 - val_loss: 0.4299 - val_accuracy: 0.7954\n",
      "Epoch 18/100\n",
      "783/783 [==============================] - 4s 5ms/step - loss: 0.4193 - accuracy: 0.7983 - val_loss: 0.4305 - val_accuracy: 0.7908\n",
      "Epoch 19/100\n",
      "783/783 [==============================] - 4s 5ms/step - loss: 0.4194 - accuracy: 0.7957 - val_loss: 0.4248 - val_accuracy: 0.7885\n",
      "Epoch 20/100\n",
      "783/783 [==============================] - 4s 5ms/step - loss: 0.4175 - accuracy: 0.7983 - val_loss: 0.4259 - val_accuracy: 0.7897\n",
      "Epoch 21/100\n",
      "783/783 [==============================] - 4s 5ms/step - loss: 0.4165 - accuracy: 0.8020 - val_loss: 0.4278 - val_accuracy: 0.7908\n",
      "Epoch 22/100\n",
      "783/783 [==============================] - 4s 5ms/step - loss: 0.4133 - accuracy: 0.7994 - val_loss: 0.4297 - val_accuracy: 0.7943\n",
      "Epoch 23/100\n",
      "783/783 [==============================] - 4s 5ms/step - loss: 0.4118 - accuracy: 0.7999 - val_loss: 0.4310 - val_accuracy: 0.7782\n",
      "Epoch 24/100\n",
      "783/783 [==============================] - 4s 5ms/step - loss: 0.4197 - accuracy: 0.7975 - val_loss: 0.4329 - val_accuracy: 0.7897\n",
      "Epoch 25/100\n",
      "783/783 [==============================] - 4s 5ms/step - loss: 0.4094 - accuracy: 0.8011 - val_loss: 0.4261 - val_accuracy: 0.8034\n",
      "Epoch 26/100\n",
      "783/783 [==============================] - 4s 5ms/step - loss: 0.4060 - accuracy: 0.8029 - val_loss: 0.4245 - val_accuracy: 0.7874\n",
      "Epoch 27/100\n",
      "783/783 [==============================] - 4s 5ms/step - loss: 0.4102 - accuracy: 0.8024 - val_loss: 0.4240 - val_accuracy: 0.7920\n",
      "Epoch 28/100\n",
      "783/783 [==============================] - 4s 5ms/step - loss: 0.4048 - accuracy: 0.8039 - val_loss: 0.4156 - val_accuracy: 0.7920\n",
      "Epoch 29/100\n",
      "783/783 [==============================] - 4s 5ms/step - loss: 0.4083 - accuracy: 0.8046 - val_loss: 0.4222 - val_accuracy: 0.7931\n",
      "Epoch 30/100\n",
      "783/783 [==============================] - 4s 5ms/step - loss: 0.4036 - accuracy: 0.8077 - val_loss: 0.4124 - val_accuracy: 0.7862\n",
      "Epoch 31/100\n",
      "783/783 [==============================] - 4s 5ms/step - loss: 0.4068 - accuracy: 0.8030 - val_loss: 0.4213 - val_accuracy: 0.7816\n",
      "Epoch 32/100\n",
      "783/783 [==============================] - 4s 5ms/step - loss: 0.4010 - accuracy: 0.8049 - val_loss: 0.4165 - val_accuracy: 0.7989\n",
      "Epoch 33/100\n",
      "783/783 [==============================] - 4s 5ms/step - loss: 0.3958 - accuracy: 0.8048 - val_loss: 0.4255 - val_accuracy: 0.7943\n",
      "Epoch 34/100\n",
      "783/783 [==============================] - 4s 5ms/step - loss: 0.3942 - accuracy: 0.8079 - val_loss: 0.4251 - val_accuracy: 0.7885\n",
      "Epoch 35/100\n",
      "783/783 [==============================] - 4s 5ms/step - loss: 0.4016 - accuracy: 0.8040 - val_loss: 0.4282 - val_accuracy: 0.7805\n",
      "Epoch 36/100\n",
      "783/783 [==============================] - 4s 5ms/step - loss: 0.4012 - accuracy: 0.8046 - val_loss: 0.4274 - val_accuracy: 0.7828\n",
      "Epoch 37/100\n",
      "783/783 [==============================] - 4s 5ms/step - loss: 0.4002 - accuracy: 0.8081 - val_loss: 0.4146 - val_accuracy: 0.7943\n",
      "Epoch 38/100\n",
      "783/783 [==============================] - 4s 5ms/step - loss: 0.3928 - accuracy: 0.8079 - val_loss: 0.4289 - val_accuracy: 0.7931\n",
      "Epoch 39/100\n",
      "783/783 [==============================] - 4s 5ms/step - loss: 0.3944 - accuracy: 0.8090 - val_loss: 0.4331 - val_accuracy: 0.7851\n",
      "Epoch 40/100\n",
      "783/783 [==============================] - 4s 5ms/step - loss: 0.3981 - accuracy: 0.8081 - val_loss: 0.4287 - val_accuracy: 0.7839\n",
      "Epoch 41/100\n",
      "783/783 [==============================] - 4s 5ms/step - loss: 0.3940 - accuracy: 0.8083 - val_loss: 0.4247 - val_accuracy: 0.7989\n",
      "Epoch 42/100\n",
      "783/783 [==============================] - 4s 5ms/step - loss: 0.3995 - accuracy: 0.8051 - val_loss: 0.4364 - val_accuracy: 0.7851\n",
      "Epoch 43/100\n",
      "783/783 [==============================] - 4s 5ms/step - loss: 0.3966 - accuracy: 0.8061 - val_loss: 0.4274 - val_accuracy: 0.8034\n",
      "Epoch 44/100\n",
      "783/783 [==============================] - 4s 5ms/step - loss: 0.3971 - accuracy: 0.8071 - val_loss: 0.4173 - val_accuracy: 0.7966\n",
      "Epoch 45/100\n",
      "781/783 [============================>.] - ETA: 0s - loss: 0.3896 - accuracy: 0.8132Restoring model weights from the end of the best epoch: 25.\n",
      "783/783 [==============================] - 4s 5ms/step - loss: 0.3894 - accuracy: 0.8132 - val_loss: 0.4199 - val_accuracy: 0.7931\n",
      "Epoch 45: early stopping\n"
     ]
    }
   ],
   "source": [
    "layers_arr = [\n",
    "    [0.1,1024,1024,1024,1024],\n",
    "]\n",
    "all_history = pd.DataFrame()\n",
    "for i, l in enumerate(layers_arr):\n",
    "    #print(f\"\"\"[{i+1}/{len(layers_arr)}] - {l}{\" \"*20}\"\"\", end=\"\\r\")\n",
    "    model = create_model(l)\n",
    "    model.compile(optimizer=Adam(), loss=BinaryCrossentropy(), metrics=[\"accuracy\"])\n",
    "    history = model.fit(x_train, y_train, epochs=100, shuffle=True, batch_size=10, validation_split=0.1, verbose=1, callbacks=[callback])\n",
    "    df = pd.DataFrame(history.history)\n",
    "    all_history = pd.concat([all_history, df.set_index([[str(l)[1:-1]]*df.shape[0], df.index])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_history.to_pickle(\"model_testing_results_dropout.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_history = pd.read_pickle(\"model_testing_results_dropout.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_col = 1\n",
    "fig = make_subplots(\n",
    "    rows=len(all_history.columns)//nb_col+1 if len(all_history.columns)%nb_col else len(all_history.columns)//nb_col,\n",
    "    cols=nb_col,\n",
    "    subplot_titles=all_history.columns\n",
    ")\n",
    "for i, col in enumerate(all_history.columns):\n",
    "    for ind in all_history.index.get_level_values(0).unique():\n",
    "        fig.add_trace(go.Scatter(\n",
    "            y=all_history.loc[ind, col],\n",
    "            mode=\"lines+markers\",\n",
    "            name=ind\n",
    "        ),row=i//nb_col+1, col=i%nb_col+1)\n",
    "fig.update_layout(\n",
    "    height=1500//nb_col\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_history.sort_values(\"val_accuracy\", ascending=False)[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model_0.80780.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"model1.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "272/272 [==============================] - 1s 2ms/step - loss: 0.3656 - accuracy: 0.8256\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3655907213687897, 0.8256068229675293]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(x_test).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(max_iter=1000)\n",
    "logreg.fit(x_train, y_train.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7723455653974463"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Age', -0.9214733715215058),\n",
       " ('CryoSleep_False', -0.551744088765526),\n",
       " ('CryoSleep_True', 1.3500144996706276),\n",
       " ('Deck_A', -0.3864996390218637),\n",
       " ('Deck_B', 0.4687110689660122),\n",
       " ('Deck_C', 0.6835940306360718),\n",
       " ('Deck_D', 0.019243026467506738),\n",
       " ('Deck_E', -0.26832646172707336),\n",
       " ('Deck_F', 0.15654923443992338),\n",
       " ('Deck_G', -0.21405342704288402),\n",
       " ('Deck_T', -0.16024728630302268),\n",
       " ('Destination_55 Cancri e', 0.035599806781618226),\n",
       " ('Destination_PSO J318.5-22', -0.3165992972540114),\n",
       " ('Destination_TRAPPIST-1e', -0.3173018316754298),\n",
       " ('FoodCourt', 4.753345077891745),\n",
       " ('Group_01', -0.028268218220210983),\n",
       " ('Group_02', 0.05486841186073854),\n",
       " ('Group_03', 0.2847833041748906),\n",
       " ('Group_04', 0.16167792512313078),\n",
       " ('Group_05', -0.1501668033648223),\n",
       " ('Group_06', 0.09507211935676513),\n",
       " ('Group_07', -0.2266600577103713),\n",
       " ('Group_08', -0.13765978576819163),\n",
       " ('HomePlanet_Earth', -0.34316243141680086),\n",
       " ('HomePlanet_Europa', 0.7841459313266589),\n",
       " ('HomePlanet_Mars', 0.08499345834105249),\n",
       " ('Num', 0.3428512380729576),\n",
       " ('RoomService', -8.516007971787621),\n",
       " ('ShoppingMall', 5.131861006525028),\n",
       " ('Side_P', -0.10599816147370428),\n",
       " ('Side_S', 0.4049687078883643),\n",
       " ('Spa', -11.791213749154148),\n",
       " ('VRDeck', -11.160567261598457)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(clean_train_data.columns, logreg.coef_[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = logreg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6085, 33), (2608, 33), (6085, 1), (2608, 1))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tr, x_va, y_tr, y_va = train_test_split(x_train, y_train, test_size=0.3)\n",
    "x_tr.shape, x_va.shape, y_tr.shape, y_va.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "            'depth':[3,1,2,6,4,5],\n",
    "            'iterations':[250,100,500],\n",
    "            'learning_rate':[0.03,0.001,0.01,0.1,0.2,0.3],\n",
    "            'l2_leaf_reg':[3,1,5,10,100],\n",
    "            'border_count':[32,5,10,20,50,100,200],\n",
    "            'bagging_temperature':[0.03,0.09,0.25,0.75],\n",
    "            'random_strength':[0.2,0.5,0.8],\n",
    "            'max_ctr_complexity':[1,2,3,4,5]\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x2358b3ca5c0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catb = CatBoostClassifier(\n",
    "    iterations=2000,\n",
    "    learning_rate=0.5,\n",
    "    random_strength=0.1,\n",
    ")\n",
    "catb.fit(x_tr, y_tr, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8052147239263804"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catb.score(x_va, y_va.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = catb.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_bool = np.where(prediction <= 0.5, 0, 1).astype(bool)\n",
    "submission = pd.DataFrame({\n",
    "    \"PassengerId\": test_data.PassengerId.values,\n",
    "    \"Transported\": prediction_bool,\n",
    "}).set_index(\"PassengerId\")\n",
    "submission.to_csv(\"submission.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0986a705e0e9c41aedb0cb54b09a403593fe0a5bc8bc18fb428b786d741665bc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
